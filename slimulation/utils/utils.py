import logging
import sys
import time
import json
import re
import shutil
from typing import Any, Dict, List
from pathlib import Path

def merge_two_jsonl_file(file1_path: Path, file2_path: Path, output_path: Path) -> None:
    """
    Merge two JSONL files into one, writing the combined lines to output_path.
    If a key "id" is present in each JSON object, de-duplicate by "id",
    keeping the object from file2 if duplicates exist.

    Args:
        file1_path (Path): Path to the first JSONL file.
        file2_path (Path): Path to the second JSONL file.
        output_path (Path): Path to save the merged JSONL output.
    """
    seen = {}

    # if file1 does not exist, save file2 to output_path
    if not file1_path.exists():
        shutil.copy(file2_path, output_path)
        logging.info(f"File {file1_path} does not exist, copying {file2_path} to {output_path}")
        return
    elif not file2_path.exists():
        shutil.copy(file1_path, output_path)
        logging.info(f"File {file2_path} does not exist, copying {file1_path} to {output_path}")
        return

    # First read file1
    with file1_path.open("r", encoding="utf-8") as f1:
        for line in f1:
            obj = json.loads(line)
            obj_id = obj.get("id")
            if obj_id is not None:
                seen[obj_id] = obj
            else:
                # If no id, use str(line) as key to avoid simple duplicates
                seen[str(line).strip()] = obj

    # Then read file2, overwrite if duplicate id/line
    with file2_path.open("r", encoding="utf-8") as f2:
        for line in f2:
            obj = json.loads(line)
            obj_id = obj.get("id")
            if obj_id is not None:
                seen[obj_id] = obj
            else:
                seen[str(line).strip()] = obj

    # Write combined data to output_path
    with output_path.open("w", encoding="utf-8") as out:
        for obj in seen.values():
            out.write(json.dumps(obj, ensure_ascii=False) + "\n")

def setup_logging(result_dir: Path) -> logging.Logger:
    """Setup logging to both console and file."""
    result_dir.mkdir(parents=True, exist_ok=True)
    log_path = result_dir / "eval.log"
    
    # Remove existing handlers
    for handler in logging.root.handlers[:]:
        logging.root.removeHandler(handler)

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s",
        handlers=[
            logging.FileHandler(log_path, mode="w", encoding="utf-8"),
            logging.StreamHandler(sys.stdout)
        ]
    )
    return logging.getLogger("eval")

def display_metrics_report(metrics_data: Dict[str, Dict[str, float]]):
    if not metrics_data:
        print("No metrics data to display.")
        return

    print("\n" + "="*60)
    print(f"{'Dataset':<25} | {'Avg@K':<12} | {'Pass@K':<12}")
    print("-" * 60)

    # 优先打印 overall（如果存在）
    if "overall" in metrics_data:
        stats = metrics_data["overall"]
        avg_k = stats["avg_k"]
        pass_k = stats["pass_k"]
        print(f"{'overall':<25} | {avg_k:>11.2%} | {pass_k:>11.2%}")
        print("-" * 60)

    for ds_name, stats in metrics_data.items():
        if ds_name == "overall":
            continue
        avg_k = stats["avg_k"]
        pass_k = stats["pass_k"]
        print(f"{ds_name:<25} | {avg_k:>11.2%} | {pass_k:>11.2%}")
        
    print("="*60 + "\n")

def calculate_and_print_metrics(eval_output_file: Path, cache_dir: str = None):
    from slimulation.reward.reward import extract_metrics_from_file
    results = extract_metrics_from_file(eval_output_file)
    display_metrics_report(results)
